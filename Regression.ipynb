{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218693d0-51c0-459c-b615-98de5792b165",
   "metadata": {},
   "source": [
    "#### Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each.\n",
    "- **Simple Linear Regression**: Models the relationship between two variables—one dependent (Y) and one independent (X). The equation is:\n",
    "  $\n",
    "  Y = \\beta_0 + \\beta_1 X\n",
    "  $\n",
    "  **Example**: Predicting house prices based on size. Here, size (X) is the independent variable, and price (Y) is the dependent variable.\n",
    "\n",
    "- **Multiple Linear Regression**: Models the relationship between one dependent variable and two or more independent variables. The equation is:\n",
    "  $\n",
    "  Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_n X_n\n",
    "  $\n",
    "  **Example**: Predicting house prices based on size, number of bedrooms, and location. Here, size, bedrooms, and location are independent variables, and price is the dependent variable.\n",
    "\n",
    "#### Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?\n",
    "The key assumptions of linear regression are:\n",
    "\n",
    "- **Linearity**: The relationship between the independent and dependent variables is linear.  \n",
    "  *Check*: Use scatter plots or correlation analysis.\n",
    "\n",
    "- **Independence**: The residuals (errors) are independent.  \n",
    "  *Check*: Use the Durbin-Watson test.\n",
    "\n",
    "- **Homoscedasticity**: Constant variance of errors.  \n",
    "  *Check*: Use residual plots.\n",
    "\n",
    "- **Normality**: The residuals should be normally distributed.  \n",
    "  *Check*: Use Q-Q plots or the Shapiro-Wilk test.\n",
    "\n",
    "- **No multicollinearity**: Independent variables should not be highly correlated.  \n",
    "  *Check*: Use Variance Inflation Factor (VIF) or a correlation matrix.\n",
    "\n",
    "#### Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario.\n",
    "- **Slope** (\\(\\beta_1\\)): Represents the change in the dependent variable (Y) for a one-unit change in the independent variable (X), holding other factors constant.\n",
    "  \n",
    "- **Intercept** (\\(\\beta_0\\)): Represents the expected value of Y when X = 0.\n",
    "\n",
    "**Example**: If we model the price of a house based on its size, the slope indicates how much the price increases for each additional square foot. The intercept represents the predicted price of a house when the size is 0 (which may not have real-world meaning in some contexts).\n",
    "\n",
    "### Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "Gradient Descent is an optimization algorithm used to minimize the cost function in machine learning models. It works by iteratively adjusting the model parameters (e.g., weights in linear regression) in the direction of the steepest descent of the cost function until the minimum is reached.\n",
    "\n",
    "**Steps**:\n",
    "1. Initialize parameters randomly.\n",
    "2. Compute the gradient of the cost function with respect to the parameters.\n",
    "3. Update the parameters by subtracting the gradient scaled by a learning rate.\n",
    "4. Repeat until convergence.\n",
    "\n",
    "In linear regression, gradient descent helps find the optimal values of coefficients that minimize the error.\n",
    "\n",
    "### Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "Multiple Linear Regression models the relationship between one dependent variable (Y) and two or more independent variables (X₁, X₂, ..., Xₙ). The equation is:\n",
    "\n",
    "$\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_n X_n + \\epsilon\n",
    "$\n",
    "\n",
    "It differs from **Simple Linear Regression**, which only involves one independent variable (X₁). Multiple linear regression allows for a more complex analysis where more factors (independent variables) are involved.\n",
    "\n",
    "### Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?\n",
    "**Multicollinearity** occurs when two or more independent variables in a multiple regression model are highly correlated. This can make it difficult to determine the effect of each variable individually.\n",
    "\n",
    "**Detection**:\n",
    "- Check the Variance Inflation Factor (VIF): A VIF above 10 indicates multicollinearity.\n",
    "- Use correlation matrices to detect highly correlated variables.\n",
    "\n",
    "**Addressing**:\n",
    "- Remove one of the correlated variables.\n",
    "- Use Principal Component Analysis (PCA) to reduce the dimensionality.\n",
    "- Regularization techniques like Ridge or Lasso regression can also help mitigate multicollinearity.\n",
    "\n",
    "### Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "**Polynomial Regression** is a type of regression that models the relationship between the independent variable(s) and the dependent variable as an nth-degree polynomial. The equation is:\n",
    "\n",
    "$\n",
    "Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\dots + \\beta_n X^n\n",
    "$\n",
    "\n",
    "Unlike **Linear Regression**, which assumes a linear relationship, polynomial regression can model more complex, nonlinear relationships by adding powers of the independent variable(s).\n",
    "\n",
    "### Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?\n",
    "**Advantages**:\n",
    "- Can model complex, nonlinear relationships between variables.\n",
    "\n",
    "**Disadvantages**:\n",
    "- Prone to overfitting, especially with higher-degree polynomials.\n",
    "- More computationally expensive.\n",
    "\n",
    "**When to use**:\n",
    "- When the data shows a clear nonlinear trend that a linear model cannot capture.\n",
    "- If residuals from a linear regression model show a systematic pattern, indicating that a more complex model like polynomial regression might fit better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e080a-9abb-4233-ba73-455ce7e74ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
