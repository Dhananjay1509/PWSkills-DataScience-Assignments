{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8facd15d-a7d5-4cd2-8b94-bcac8306a433",
   "metadata": {},
   "source": [
    "#### Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\n",
    "#### Assumptions for ANOVA:\n",
    "1. **Independence of Observations**: Each group's data should be collected independently of the others.\n",
    "    - **Violation Example**: Using repeated measures on the same subjects without accounting for the repeated nature of the measurements can violate this assumption.\n",
    "  \n",
    "2. **Normality**: The data in each group should be normally distributed.\n",
    "    - **Violation Example**: A heavily skewed distribution (e.g., salary data with a few high-income outliers) might violate this assumption.\n",
    "  \n",
    "3. **Homogeneity of Variances (Homoscedasticity)**: The variances across the groups should be approximately equal.\n",
    "    - **Violation Example**: If one group's variance is significantly higher or lower than others (e.g., one group has much more variability in test scores), this assumption is violated.\n",
    "\n",
    "#### Impact of Violations:\n",
    "1. **Independence**: Violating independence can lead to incorrect inferences, as it may inflate Type I error rates (false positives).\n",
    "2. **Normality**: If the normality assumption is violated, the ANOVA test may become less reliable, particularly with small sample sizes.\n",
    "3. **Homogeneity of Variances**: Violating this assumption can lead to incorrect conclusions because the F-statistic can be biased if the variances differ substantially.\n",
    "\n",
    "---\n",
    "\n",
    "#### Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "1. **One-Way ANOVA**: Used when comparing the means of three or more independent groups based on one factor or independent variable.\n",
    "   - **Situation**: Testing if there is a difference in average exam scores among students from three different schools.\n",
    "\n",
    "2. **Two-Way ANOVA**: Used to evaluate the effect of two factors simultaneously and determine if there is an interaction between them.\n",
    "   - **Situation**: Assessing the impact of two independent factors (e.g., teaching method and gender) on students' test scores.\n",
    "\n",
    "3. **Repeated Measures ANOVA**: Used when the same subjects are measured more than once (e.g., across different time points or conditions).\n",
    "   - **Situation**: Evaluating the effectiveness of a diet plan by measuring the weight of participants at multiple time points.\n",
    "\n",
    "---\n",
    "\n",
    "#### Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "#### Partitioning of Variance in ANOVA:\n",
    "1. **Total Variance (SST)**: The overall variability in the data, which is the sum of the variability between groups (SSB) and the variability within groups (SSW).\n",
    "2. **Between-Group Variance (SSB)**: The portion of the total variance that is due to the differences between group means.\n",
    "3. **Within-Group Variance (SSW)**: The portion of the total variance that is due to the variability within each group.\n",
    "\n",
    "#### Importance:\n",
    "- Understanding the partitioning of variance is crucial because it helps to determine whether the observed differences in group means are statistically significant or could have occurred by random chance. It also provides insight into the proportion of total variability explained by the grouping factor, which is important for interpreting the effect size in an ANOVA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba0a07-9544-4f2d-a536-08fe4413d10e",
   "metadata": {},
   "source": [
    "#### Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042706fb-ef25-479b-b5b6-a0d22129f810",
   "metadata": {},
   "source": [
    "#### Sum of Squares in One-Way ANOVA\n",
    "\n",
    "To calculate the **Total Sum of Squares (SST)**, **Explained Sum of Squares (SSE)**, and **Residual Sum of Squares (SSR)** in a one-way ANOVA, you can use the following formulas:\n",
    "\n",
    "1. **Total Sum of Squares (SST):**\n",
    "   The total variation in the data. It is the sum of the squared differences between each observation and the overall mean.\n",
    "   \n",
    "   $$ SST = \\sum_{i=1}^{N} (y_i - \\bar{y})^2 $$\n",
    "\n",
    "2. **Explained Sum of Squares (SSE):**\n",
    "   The variation explained by the groups. It is the sum of the squared differences between the group means and the overall mean.\n",
    "   \n",
    "   $$ SSE = \\sum_{j=1}^{k} n_j (\\bar{y}_j - \\bar{y})^2 $$\n",
    "\n",
    "3. **Residual Sum of Squares (SSR):**\n",
    "   The variation that is not explained by the groups. It is the sum of the squared differences between each observation and its group mean.\n",
    "   \n",
    "   $$ SSR = \\sum_{j=1}^{k} \\sum_{i=1}^{n_j} (y_{ij} - \\bar{y}_j)^2 $$\n",
    "\n",
    "#### Explanation:\n",
    "- $ y_i $ is an individual observation.\n",
    "- $ \\bar{y} $ is the overall mean of the data.\n",
    "- $ \\bar{y}_j $ is the mean of group $ j $.\n",
    "- $ n_j $ is the number of observations in group $ j $.\n",
    "- $ N $ is the total number of observations across all groups.\n",
    "- $ k $ is the number of groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "647a2dae-388a-499c-a159-9d3d216d658c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 12.0\n",
      "Explained Sum of Squares (SSE): 6.0\n",
      "Residual Sum of Squares (SSR): 6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Example data\n",
    "data = {\n",
    "    'Group': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'Value': [4, 5, 6, 5, 6, 7, 6, 7, 8]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group by 'Group' and calculate the group means and overall mean\n",
    "group_means = df.groupby('Group')['Value'].mean()\n",
    "overall_mean = df['Value'].mean()\n",
    "\n",
    "# Calculate SST (Total Sum of Squares)\n",
    "sst = np.sum((df['Value'] - overall_mean) ** 2)\n",
    "\n",
    "# Calculate SSE (Sum of Squares Between Groups)\n",
    "sse = np.sum(df.groupby('Group').size() * (group_means - overall_mean) ** 2)\n",
    "\n",
    "# Calculate SSR (Sum of Squares Within Groups)\n",
    "ssr = np.sum((df['Value'] - df.groupby('Group')['Value'].transform('mean')) ** 2)\n",
    "\n",
    "print(f\"Total Sum of Squares (SST): {sst}\")\n",
    "print(f\"Explained Sum of Squares (SSE): {sse}\")\n",
    "print(f\"Residual Sum of Squares (SSR): {ssr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41375396-9eba-41ef-a141-1633b96b6886",
   "metadata": {},
   "source": [
    "#### Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "\n",
    "##### Two-Way ANOVA with Main and Interaction Effects using Python\n",
    "\n",
    "In this guide, we'll calculate the main effects and interaction effects in a two-way ANOVA using Python's `statsmodels` library. A two-way ANOVA helps in understanding how two categorical independent variables impact a continuous dependent variable, both individually (main effects) and together (interaction effects).\n",
    "\n",
    "##### Step-by-Step Process\n",
    "\n",
    "###### 1. Prepare the Data\n",
    "Make sure your data is organized into a Pandas DataFrame, with columns for the dependent variable and the two independent variables (factors).\n",
    "\n",
    "###### 2. Fit the ANOVA Model\n",
    "Use the `ols` (Ordinary Least Squares) function from `statsmodels.formula.api` to specify the model formula, and fit the model.\n",
    "\n",
    "###### 3. Calculate the ANOVA Table\n",
    "Use the `anova_lm` function from `statsmodels` to compute the ANOVA table, which will include the main and interaction effects.\n",
    "\n",
    "##### Example Code\n",
    "\n",
    "Here's how to calculate the main and interaction effects using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c328f36b-0d04-4fb9-8676-c63905d230d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             sum_sq   df             F    PR(>F)\n",
      "C(FactorA)             1.333333e+00  1.0  8.000000e-01  0.397204\n",
      "C(FactorB)             5.365644e-30  1.0  3.219386e-30  1.000000\n",
      "C(FactorA):C(FactorB)  3.333333e-01  1.0  2.000000e-01  0.666581\n",
      "Residual               1.333333e+01  8.0           NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example Data: Create a dataset with two factors (FactorA and FactorB) and a dependent variable (Y)\n",
    "data = pd.DataFrame({\n",
    "    'FactorA': ['A1', 'A1', 'A1', 'A2', 'A2', 'A2', 'A1', 'A1', 'A1', 'A2', 'A2', 'A2'],\n",
    "    'FactorB': ['B1', 'B1', 'B1', 'B1', 'B1', 'B1', 'B2', 'B2', 'B2', 'B2', 'B2', 'B2'],\n",
    "    'Y': [8, 9, 6, 7, 9, 6, 7, 8, 9, 6, 7, 8]\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Y ~ C(FactorA) + C(FactorB) + C(FactorA):C(FactorB)', data=data).fit()\n",
    "\n",
    "# Calculate the ANOVA table\n",
    "anova_results = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Display the results\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcfa60c-4c24-4f3d-8974-973fbd378814",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "##### OLS Function\n",
    "\n",
    "Specifies and fits the OLS regression model. The model is defined as follows:\n",
    "\n",
    "`Y ~ C(FactorA) + C(FactorB) + C(FactorA):C(FactorB)`\n",
    "\n",
    "Where:\n",
    "- **Y**: Dependent variable.\n",
    "- **C(FactorA)**: Categorical variable for Factor A.\n",
    "- **C(FactorB)**: Categorical variable for Factor B.\n",
    "- **C(FactorA):C(FactorB)**: Interaction term between Factor A and Factor B.\n",
    "\n",
    "##### anova_lm Function\n",
    "\n",
    "Generates the ANOVA table from the fitted model. `typ=2` specifies the use of Type II sum of squares, commonly used in two-way ANOVA.\n",
    "\n",
    "##### Output\n",
    "\n",
    "The output will be an ANOVA table containing:\n",
    "\n",
    "- **Sum of Squares (SS)**: For each effect (Factor A, Factor B, Interaction, and Residual).\n",
    "- **Degrees of Freedom (DF)**: For each effect.\n",
    "- **F-statistic**: The F-value for the hypothesis test for each effect.\n",
    "- **p-value**: The significance level for each effect.\n",
    "\n",
    "By interpreting this table, you can determine the main effects of each factor and their interaction effect on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e74ecf-0f78-4350-9dd7-07a1e2402ebd",
   "metadata": {},
   "source": [
    "#### Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?\n",
    "\n",
    "##### F-Statistic (5.23)\n",
    "\n",
    "The F-statistic is a ratio that compares the variance between the group means to the variance within the groups. An F-statistic of 5.23 indicates that there is more variance between the group means than would be expected by chance alone.\n",
    "\n",
    "##### p-value (0.02)\n",
    "\n",
    "The p-value tells us the probability of observing an F-statistic as extreme as 5.23 if the null hypothesis were true. The null hypothesis in a one-way ANOVA typically states that all group means are equal. A p-value of 0.02 suggests that there is only a 2% chance that the observed differences in group means occurred by random chance under the null hypothesis.\n",
    "\n",
    "##### Conclusion\n",
    "\n",
    "Since the p-value (0.02) is less than the common significance level (α = 0.05), you would reject the null hypothesis.  \n",
    "This means there is sufficient evidence to conclude that at least one group mean is significantly different from the others.\n",
    "\n",
    "##### Interpretation\n",
    "\n",
    "The results suggest that there are statistically significant differences between the means of the groups being compared.  \n",
    "However, the ANOVA does not indicate which specific groups are different from each other; it only tells you that at least one group is different. To determine which specific groups differ, you would need to conduct a post hoc test (such as Tukey's HSD or Bonferroni correction).\n",
    "\n",
    "##### In summary:\n",
    "\n",
    "There is significant evidence to suggest differences in the means between at least some of the groups, with the probability of this finding occurring by chance being 2%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf5406a-883d-43fa-88f1-2ac2b1698b79",
   "metadata": {},
   "source": [
    "#### Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data? \n",
    "Handling missing data in repeated measures ANOVA is critical to ensure accurate results. Several methods can be applied to handle missing data, each with its own implications:\n",
    "\n",
    "##### Methods for Handling Missing Data:\n",
    "\n",
    "- **Listwise Deletion:**  \n",
    "  Removes all cases with missing data from the analysis. This method is straightforward but can reduce the sample size and statistical power, especially if many observations are missing. It assumes that data is missing completely at random (MCAR), which may not always be the case.\n",
    "\n",
    "- **Pairwise Deletion:**  \n",
    "  Uses all available data for each analysis without excluding cases entirely. This can retain more data but may introduce bias if the data is not missing at random (MAR or MNAR). It may also result in varying sample sizes for different comparisons.\n",
    "\n",
    "- **Mean Imputation:**  \n",
    "  Replaces missing values with the mean of the observed values for that variable. While easy to implement, this method can underestimate variability and lead to biased parameter estimates, especially if the data is not MCAR.\n",
    "\n",
    "- **Last Observation Carried Forward (LOCF):**  \n",
    "  Fills in missing values with the participant's last observed data point. This method assumes no change after the last observation, which may not be valid and can introduce bias if the missing data is not random.\n",
    "\n",
    "- **Multiple Imputation:**  \n",
    "  Generates multiple datasets by replacing missing values with plausible estimates, and then combines the results from these datasets. This approach accounts for the uncertainty due to missing data and is generally recommended as it provides more accurate parameter estimates, assuming data is MAR.\n",
    "\n",
    "##### Consequences of Different Methods:\n",
    "\n",
    "- **Loss of Power:**  \n",
    "  Listwise deletion can significantly reduce sample size, leading to a loss of statistical power.\n",
    "\n",
    "- **Bias in Estimates:**  \n",
    "  Methods like mean imputation or LOCF can introduce bias if the missing data is not random.\n",
    "\n",
    "- **Incorrect Variance Estimates:**  \n",
    "  Some methods may underestimate the true variability in the data, resulting in incorrect inferences.\n",
    "\n",
    "- **Reduced Validity of Results:**  \n",
    "  Multiple imputation is preferred as it typically leads to more valid statistical inferences by accounting for the uncertainty due to missing data.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c930b-66a5-44b0-9236-3f0e8ba06ae1",
   "metadata": {},
   "source": [
    "#### Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "Post-hoc tests are used after a significant ANOVA result to identify which specific groups differ from each other. Here are some common post-hoc tests and their uses:\n",
    "\n",
    "##### Tukey's Honest Significant Difference (HSD):\n",
    "- **When to Use:**  \n",
    "  Appropriate when you have equal group sizes and want to control for the Type I error rate while comparing all possible pairs of means. It is a common choice for pairwise comparisons.\n",
    "\n",
    "- **Example:**  \n",
    "  After finding a significant difference in the mean scores of students taught using four different teaching methods, Tukey's HSD can determine which specific teaching methods differ.\n",
    "\n",
    "##### Bonferroni Correction:\n",
    "- **When to Use:**  \n",
    "  Suitable when conducting multiple pairwise comparisons to control the family-wise error rate. It is more conservative and adjusts the significance level for the number of comparisons.\n",
    "\n",
    "- **Example:**  \n",
    "  When comparing the effectiveness of five different diets on weight loss, Bonferroni correction reduces the chance of Type I errors from multiple comparisons.\n",
    "\n",
    "##### Scheffé's Test:\n",
    "- **When to Use:**  \n",
    "  Useful for making complex comparisons, including non-pairwise comparisons (e.g., comparing combinations of groups). It is more conservative and flexible than Tukey's HSD.\n",
    "\n",
    "- **Example:**  \n",
    "  If researchers want to compare not only individual medications but also combinations of different treatments, Scheffé's test would be suitable.\n",
    "\n",
    "##### Dunnett's Test:\n",
    "- **When to Use:**  \n",
    "  Ideal when comparing multiple treatment groups to a single control group. It controls the Type I error rate while making these specific comparisons.\n",
    "\n",
    "- **Example:**  \n",
    "  In a drug trial comparing a new drug to a placebo and a standard drug, Dunnett's test would be used to compare the new drug directly to the placebo and standard drug.\n",
    "\n",
    "##### Example Situation for Post-hoc Tests:  \n",
    "After performing a one-way ANOVA to assess the effect of four different fertilizers on plant growth, you find a significant difference among the groups. Since ANOVA only indicates that at least one group differs, a post-hoc test, such as Tukey's HSD, would be necessary to determine which specific fertilizers differ in their effect on plant growth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6a2c95-3cbb-4bea-bb50-495f03e97832",
   "metadata": {},
   "source": [
    "#### Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results.\n",
    "\n",
    "- To conduct a one-way ANOVA to compare the mean weight loss of three diets (A, B, and C), we first need to simulate or assume some data, as you didn't provide specific values. The one-way ANOVA test is used to determine whether there are any statistically significant differences between the means of three or more independent (unrelated) groups.\n",
    "\n",
    "Let's assume the weight loss data for 50 participants divided into three groups (each following a different diet). I'll create some sample data and perform the ANOVA test using Python.\n",
    "\n",
    "Here is the code to perform the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7cfcd88-8aa0-43a5-a67a-ce3969a13f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 2.174\n",
      "p-value: 0.125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Simulate some data for weight loss for three different diets\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Simulated weight loss data for diets A, B, and C (in kg)\n",
    "diet_A = np.random.normal(loc=5, scale=2, size=16)  # Mean = 5, Std = 2, n = 16\n",
    "diet_B = np.random.normal(loc=4.5, scale=2.5, size=17)  # Mean = 4.5, Std = 2.5, n = 17\n",
    "diet_C = np.random.normal(loc=6, scale=1.8, size=17)  # Mean = 6, Std = 1.8, n = 17\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "F_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Output the results\n",
    "print(f\"F-statistic: {F_statistic:.3f}\")\n",
    "print(f\"p-value: {p_value:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5e6fce-ed9f-4f13-b2bc-3253498621fb",
   "metadata": {},
   "source": [
    "#### Interpreting the Results\n",
    "- F-statistic: Measures the ratio of between-group variance to within-group variance. A higher F-statistic indicates greater variance among the group means.\n",
    "- p-value: Tells us whether the observed differences are statistically significant. Typically, a p-value less than 0.05 is considered significant, indicating that there is a statistically significant difference between at least two of the diet groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c19f1d9-2b29-44f0-a849-eac9d377f62e",
   "metadata": {},
   "source": [
    "#### Q10. A company wants to know if there are any significant differences in the average time it takes tocomplete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "\n",
    "- To conduct a two-way ANOVA, we need to examine the effects of two independent variables on a dependent variable. In this case, we have two independent variables: the software program (Program A, B, and C) and the employee experience level (novice vs. experienced). The dependent variable is the time it takes to complete the task.\n",
    "\n",
    "- To perform a two-way ANOVA in Python, we can use the statsmodels library, which provides tools for conducting ANOVA and regression analysis. Since no specific data is provided, we will create a simulated dataset.\n",
    "\n",
    "Here is the code to perform the two-way ANOVA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b774da53-6cda-42c9-a5b9-79480f8d711a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               sum_sq    df          F    PR(>F)\n",
      "C(Software)                357.276664   2.0  10.947864  0.000418\n",
      "C(Experience)              194.061665   1.0  11.893084  0.002092\n",
      "C(Software):C(Experience)    3.360483   2.0   0.102974  0.902547\n",
      "Residual                   391.612478  24.0        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Simulate data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Creating data for 30 employees (15 novice, 15 experienced)\n",
    "data = {\n",
    "    'Software': np.repeat(['A', 'B', 'C'], 10),\n",
    "    'Experience': ['Novice'] * 5 + ['Experienced'] * 5 + ['Novice'] * 5 + ['Experienced'] * 5 + ['Novice'] * 5 + ['Experienced'] * 5,\n",
    "    'Time': np.concatenate([\n",
    "        np.random.normal(30, 5, 5),  # Program A - Novice\n",
    "        np.random.normal(25, 5, 5),  # Program A - Experienced\n",
    "        np.random.normal(35, 5, 5),  # Program B - Novice\n",
    "        np.random.normal(30, 5, 5),  # Program B - Experienced\n",
    "        np.random.normal(40, 5, 5),  # Program C - Novice\n",
    "        np.random.normal(35, 5, 5)   # Program C - Experienced\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76112d6-0a07-4485-9034-aae341ebd443",
   "metadata": {},
   "source": [
    "#### Interpreting the Results\n",
    "The ANOVA table generated by the code will contain:\n",
    "\n",
    "- F-statistics: For each factor (Software, Experience) and their interaction (Software * Experience), it represents the ratio of the variance between the groups to the variance within the groups.\n",
    "- p-values: These values indicate whether the main effects (Software, Experience) or interaction effect (Software * Experience) are statistically significant. If a p-value is less than 0.05, the corresponding effect is considered significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d361cf43-970f-4dc4-abeb-506fb9c71e37",
   "metadata": {},
   "source": [
    "#### Q11. An educational researcher is interested in whether a new teaching method improves student testscores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other.\n",
    "\n",
    "To conduct a two-sample t-test and follow up with a post-hoc test if needed, you can use Python with libraries such as `scipy` and `statsmodels`. Here’s how you can do it:\n",
    "\n",
    "**1. Two-Sample T-Test**\n",
    "First, let’s perform the two-sample t-test using `scipy.stats.ttest_ind`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c89c97-fe46-4b2f-beaa-dca87ab95928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -3.0031208261723967\n",
      "P-value: 0.003391318551039432\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Generate example data\n",
    "# Assume we have test scores for each group\n",
    "np.random.seed(42)  # For reproducibility\n",
    "control_scores = np.random.normal(loc=75, scale=10, size=50)  # Traditional method\n",
    "experimental_scores = np.random.normal(loc=78, scale=10, size=50)  # New method\n",
    "\n",
    "# Perform the two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537366c0-d5d1-48f3-aed5-d542ebcd69e6",
   "metadata": {},
   "source": [
    "**2. Post-Hoc Test**\n",
    "For the post-hoc test, if the two-sample t-test shows a significant difference, you might want to perform a more detailed analysis to determine which groups differ. If you have more than two groups, a common approach is to use ANOVA followed by Tukey's HSD test. Since we only have two groups here, the t-test is sufficient.\n",
    "\n",
    "If you had multiple groups, you’d use `statsmodels` for ANOVA and Tukey's HSD as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f0627a0-ecae-4a14-895c-8140f7082ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               sum_sq    df         F    PR(>F)\n",
      "group      737.814378   1.0  9.018735  0.003391\n",
      "Residual  8017.289732  98.0       NaN       NaN\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental   5.4325 0.0034 1.8427 9.0224   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Combine data into a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'scores': np.concatenate([control_scores, experimental_scores]),\n",
    "    'group': ['Control'] * 50 + ['Experimental'] * 50\n",
    "})\n",
    "\n",
    "# Perform ANOVA\n",
    "model = ols('scores ~ group', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "# If ANOVA is significant, perform Tukey's HSD\n",
    "tukey = pairwise_tukeyhsd(endog=data['scores'], groups=data['group'], alpha=0.05)\n",
    "print(tukey)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655c4abc-7f77-4d49-b28c-5c964bd83c9d",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "**1.Two-Sample T-Test:** This test determines if there is a significant difference between the means of two independent groups. The null hypothesis is that the means of both groups are equal.\n",
    "\n",
    "**2. Post-Hoc Test:** If you have more than two groups and ANOVA shows significant differences, Tukey's HSD helps identify which specific groups have significant differences.\n",
    "\n",
    "In this case, with only two groups, the t-test should suffice. If the p-value is less than your significance level (usually 0.05), you can conclude there is a significant difference between the two teaching methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54416fe-d40a-4c2c-9682-7c691631dee9",
   "metadata": {},
   "source": [
    "#### Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other.\n",
    "\n",
    "To perform a repeated measures ANOVA in Python and follow up with a post-hoc test, you can use libraries such as `pandas` for data manipulation, `scipy` for statistical tests, and `statsmodels` for ANOVA and post-hoc tests. Here’s a step-by-step guide to achieving this:\n",
    "\n",
    "**1. Prepare Your Data**\n",
    "Assume you have a DataFrame `df` with columns: `Day`, `Store`, and `Sales`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b67906a-418c-4538-bc77-020ce8f0e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame creation with sample data\n",
    "data = {\n",
    "    'Day': list(range(1, 31)) * 3,\n",
    "    'Store': ['Store A']*30 + ['Store B']*30 + ['Store C']*30,\n",
    "    'Sales': list(range(100, 130)) * 3  # Replace this with actual sales data\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fe0bae-8e65-432a-923f-7cf4cc540f1c",
   "metadata": {},
   "source": [
    "**2. Conduct Repeated Measures ANOVA**\n",
    "\n",
    "You can use the `statsmodels` library for this. First, make sure to install `statsmodels` if you haven’t already:\n",
    "\n",
    "pip install statsmodels\n",
    "Then, perform the ANOVA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c98b3f6-9625-4b2a-8e3e-39114daed7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                sum_sq    df             F  PR(>F)\n",
      "C(Store)  2.466068e-26   2.0  1.591011e-28     1.0\n",
      "Residual  6.742500e+03  87.0           NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Fit the model\n",
    "model = ols('Sales ~ C(Store)', data=df).fit()\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7cf7ed-0cb8-4b16-a0c2-cc2ffc823bed",
   "metadata": {},
   "source": [
    "**3. Check Results and Perform Post-Hoc Test**\n",
    "\n",
    "If the p-value from the ANOVA table is less than 0.05, you’ll need to perform a post-hoc test to determine which stores differ significantly. The Tukey's HSD test is commonly used for this.\n",
    "\n",
    "Install the `statsmodels` library if you haven’t already:\n",
    "\n",
    "pip install statsmodels\n",
    "Here’s how you can perform the Tukey's HSD test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c828482c-2a5a-44fb-a3c0-bb6365253926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "=================================================\n",
      " group1  group2 meandiff p-adj lower upper reject\n",
      "-------------------------------------------------\n",
      "Store A Store B      0.0   1.0 -5.42  5.42  False\n",
      "Store A Store C      0.0   1.0 -5.42  5.42  False\n",
      "Store B Store C      0.0   1.0 -5.42  5.42  False\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "# Perform Tukey's HSD test\n",
    "tukey = pairwise_tukeyhsd(endog=df['Sales'], groups=df['Store'], alpha=0.05)\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518ca8da-8f76-4e5f-b1f1-2887e562d92e",
   "metadata": {},
   "source": [
    "**Summary of Steps:**\n",
    "1. Prepare the Data: Ensure it’s in the format needed for analysis.\n",
    "2. Fit the Repeated Measures ANOVA Model: Use statsmodels to fit and analyze the model.\n",
    "3. Perform Post-Hoc Test: If ANOVA results are significant, use Tukey’s HSD to identify specific differences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
