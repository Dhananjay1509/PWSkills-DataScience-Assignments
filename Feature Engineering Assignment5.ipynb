{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d4368de-5d94-4684-94da-815d56e8b4f8",
   "metadata": {},
   "source": [
    "#### Q1: Difference Between Ordinal Encoding and Label Encoding\n",
    "\n",
    "**Ordinal Encoding** assigns integer values to categories, maintaining their order. This encoding is used when the categorical variable has a natural order or ranking, such as \"Low\", \"Medium\", \"High\".\n",
    "\n",
    "**Label Encoding** also assigns integer values to categories, but does not consider any order. It is useful when there is no intrinsic order in the categorical variables, like \"Red\", \"Green\", \"Blue\".\n",
    "\n",
    "##### Example:\n",
    "\n",
    "- **Ordinal Encoding**: Use for \"Education Level\" (e.g., High School < Bachelor's < Master's < PhD).\n",
    "- **Label Encoding**: Use for \"Color\" (e.g., Red, Green, Blue) since colors don't have a specific order.\n",
    "\n",
    "#### Q2: Target Guided Ordinal Encoding\n",
    "\n",
    "**Target Guided Ordinal Encoding** assigns numbers to categories based on their relationship with the target variable. This method is useful when there is a significant correlation between the categorical feature and the target.\n",
    "\n",
    "**Example**: If you are predicting house prices and have a \"Location\" feature, you might encode locations based on their average house prices. Locations with higher prices get higher values.\n",
    "\n",
    "#### Q3: Covariance Definition and Importance\n",
    "\n",
    "**Covariance** measures the degree to which two variables change together. It indicates whether an increase in one variable will result in an increase or decrease in the other.\n",
    "\n",
    "- **Positive Covariance**: Variables tend to move in the same direction.\n",
    "- **Negative Covariance**: Variables tend to move in opposite directions.\n",
    "\n",
    "**Importance**: Covariance is used to understand the relationship between two variables in a dataset, which is essential in feature selection and multicollinearity analysis in machine learning.\n",
    "\n",
    "##### Calculation:\n",
    "\n",
    "$\n",
    "\\text{Cov}(X, Y) = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{n - 1}\n",
    "$\n",
    "\n",
    "where $X_i$ and $Y_i$ are the individual sample points, and $\\bar{X}$, $\\bar{Y}$ are their means.\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2ea5da-b85c-4224-99a5-edacc2a17f14",
   "metadata": {},
   "source": [
    "#### Q4. For a dataset with the following categorical variables: Color (red, green, blue), Size (small, medium, large), and Material (wood, metal, plastic), perform label encoding using Python's scikit-learn library. Show your code and explain the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "726ab57c-f639-44a6-b4a9-2fd7676191a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Colors:  [2 1 0]\n",
      "Encoded Sizes:  [2 1 0]\n",
      "Encoded Materials:  [2 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample data\n",
    "data = {'Color': ['red', 'green', 'blue'],\n",
    "        'Size': ['small', 'medium', 'large'],\n",
    "        'Material': ['wood', 'metal', 'plastic']}\n",
    "\n",
    "# Initialize label encoders for each feature\n",
    "le_color = LabelEncoder()\n",
    "le_size = LabelEncoder()\n",
    "le_material = LabelEncoder()\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_color = le_color.fit_transform(data['Color'])\n",
    "encoded_size = le_size.fit_transform(data['Size'])\n",
    "encoded_material = le_material.fit_transform(data['Material'])\n",
    "\n",
    "# Display the results\n",
    "print(\"Encoded Colors: \", encoded_color)\n",
    "print(\"Encoded Sizes: \", encoded_size)\n",
    "print(\"Encoded Materials: \", encoded_material)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0757ae-3537-46a9-b503-3b8552eb9cf9",
   "metadata": {},
   "source": [
    "**Output Explanation:**\n",
    "\n",
    "- Encoded Colors: `[2, 1, 0]` where Red = 2, Green = 1, Blue = 0.\n",
    "- Encoded Sizes: `[2, 1, 0]` where Small = 2, Medium = 1, Large = 0.\n",
    "- Encoded Materials: `[2, 0, 1]` where Wood = 2, Metal = 0, Plastic = 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adc7a56-d0b0-48a3-b30b-5fd7ffa212be",
   "metadata": {},
   "source": [
    "#### Q5: Covariance Matrix Calculation\n",
    "\n",
    "Given variables: Age, Income, and Education level, the covariance matrix is calculated as:\n",
    "\n",
    "\\[\n",
    "\\text{Cov} = \n",
    "\\begin{bmatrix}\n",
    "\\text{Cov(Age, Age)} & \\text{Cov(Age, Income)} & \\text{Cov(Age, Education)} \\\\\n",
    "\\text{Cov(Income, Age)} & \\text{Cov(Income, Income)} & \\text{Cov(Income, Education)} \\\\\n",
    "\\text{Cov(Education, Age)} & \\text{Cov(Education, Income)} & \\text{Cov(Education, Education)}\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "- The diagonal elements show the variance of each variable.\n",
    "- Off-diagonal elements show the covariance between pairs of variables.\n",
    "- Positive covariance indicates that variables move together; negative means they move inversely.\n",
    "\n",
    "#### Q6: Encoding Methods for Categorical Variables\n",
    "\n",
    "- **Gender:** Use Label Encoding (binary variable, Male = 0, Female = 1).\n",
    "- **Education Level:** Use Ordinal Encoding (High School < Bachelor’s < Master’s < PhD).\n",
    "- **Employment Status:** Use One-Hot Encoding (Unemployed = [1,0,0], Part-Time = [0,1,0], Full-Time = [0,0,1]).\n",
    "\n",
    "#### Q7: Covariance Calculation for Mixed Variables\n",
    "\n",
    "**Variables:**\n",
    "\n",
    "- Continuous: \"Temperature\", \"Humidity\"\n",
    "- Categorical: \"Weather Condition\" (Sunny, Cloudy, Rainy), \"Wind Direction\" (North, South, East, West)\n",
    "\n",
    "**Covariance Calculation:**\n",
    "\n",
    "1. Encode categorical variables using appropriate methods (e.g., One-Hot Encoding).\n",
    "2. Calculate covariance for all pairs of variables using the covariance formula or Python libraries like NumPy or Pandas.\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "- A covariance matrix will show relationships between each variable.\n",
    "- Positive covariance between continuous variables indicates they increase together; zero covariance between continuous and encoded categorical variables may suggest little to no linear relationship.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab790f3-0b53-4479-99f1-8d0a19364255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
